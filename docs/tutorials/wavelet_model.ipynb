{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starlet Tutorial: Modeling a Low Surface Brightness Galaxy\n",
    "\n",
    "This tutorial goes through a case where the default `ExtendedSource` models will struggle: a complex low surface brightness galaxy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word on starlets\n",
    "\n",
    "Starlets are a familly of functions that are generative of the ensemble of real matrices of finite sahpes and overcomplete. In that regard, shapelets have the flexibility to represent any pixelated 2-D profile. We take advantage of this property and use starlets to model sources with features that are too complex to be modeled with only assumptions of symmetry or monotonicity, such as irregular galaxies and spiral galaxies.\n",
    "\n",
    "But first, the usual incantation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import numpy as np\n",
    "import scarlet\n",
    "import astropy.io.fits as fits\n",
    "import sep \n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a superior colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', interpolation='none', origin=\"lower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Display Data\n",
    "\n",
    "We load the data set (an image cube with 5 bands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample images\n",
    "data = pickle.load(open(\"../../data/lsbg.pkl\", \"rb\"))\n",
    "images = data[\"images\"]\n",
    "filters = data[\"channels\"]\n",
    "psf = data[\"psfs\"]\n",
    "\n",
    "from scarlet.display import AsinhMapping\n",
    "\n",
    "stretch = 1\n",
    "Q = 5\n",
    "norm = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection Catalog\n",
    "\n",
    "Because we don't have a detection catalog, we need to build one. To avoid issues with merging peaks from different scales and false peaks at the lowest scale, we use the second scale for detection. We could use `detect = scarlet.detect.get_detect_wavelets(images, variance=0.1, scales=3)` to build a single band detection image, but we expand that method here to illustrate how to use starlet transforms in scarlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a detection image by summing the images in all bands\n",
    "# (a more rigorous approach would be to create a chi^2 coadd).\n",
    "detect_image = np.sum(images, axis=0)\n",
    "# Define a rough standard deviation for the image.\n",
    "# This does not have to be exact, as it is fit by the\n",
    "# get_multiresolution_support algorithm below.\n",
    "sigma = 0.1\n",
    "# Find the wavelet coefficients\n",
    "coeffs = scarlet.wavelet.starlet_transform(detect_image, scales=3)\n",
    "# Determine the significant coefficients\n",
    "# (as defined in Starck et. al 2011)\n",
    "M = scarlet.wavelet.get_multiresolution_support(detect_image, coeffs, sigma, K=3, epsilon=1e-1, max_iter=20)\n",
    "# Use the multi-resolution support to select only\n",
    "# the relevant pixels for detection\n",
    "detect = M * coeffs\n",
    "# We are only detecting positive peaks, so there\n",
    "# is no need to include the negative coefficients\n",
    "detect[detect<0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created two different sets of wavelet coefficents above. The first is the set of wavelet coeffiecients in the first three scales (and the residual image with lower frequency flux) and second is only those coefficients that are determined to be \"significant\" according to the algorithm in Starck et al. 2011.\n",
    "\n",
    "Below we view both sets of coefficents, and compare the reconstruction of the full set of wavelet coefficients with the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the detection coefficients\n",
    "lvl = detect.shape[0]\n",
    "plt.figure(figsize = (lvl*5+5,5))\n",
    "plt.suptitle('Wavelet coefficients')\n",
    "for i in range(lvl):\n",
    "    plt.subplot(1,lvl,i+1)\n",
    "    plt.title('scale'+str(i+1))\n",
    "    img = detect[i]\n",
    "    img = np.arcsinh(10*img)/10\n",
    "    vmax = np.max(np.abs(img))\n",
    "    plt.imshow(img, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "    plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Display the detection coefficients\n",
    "lvl = detect.shape[0]\n",
    "plt.figure(figsize = (lvl*5+5,5))\n",
    "plt.suptitle('Wavelet coefficients')\n",
    "for i in range(lvl):\n",
    "    plt.subplot(1,lvl,i+1)\n",
    "    plt.title('scale'+str(i+1))\n",
    "    img = coeffs[i]\n",
    "    img = np.arcsinh(10*img)/10\n",
    "    vmax = np.max(np.abs(img))\n",
    "    plt.imshow(img, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "    plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "reconstruction = scarlet.wavelet.starlet_reconstruction(coeffs)\n",
    "residual = detect_image - reconstruction\n",
    "\n",
    "#Making sure we recover the original image:\n",
    "plt.figure(figsize = (30,10))\n",
    "plt.subplot(131)\n",
    "plt.title('Original image', fontsize = 20)\n",
    "vmax = np.max(np.abs(detect_image))\n",
    "plt.imshow(detect_image, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(132)\n",
    "plt.title('Starlet-reconstructed image', fontsize = 20)\n",
    "vmax = np.max(np.abs(reconstruction))\n",
    "plt.imshow(reconstruction, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(133)\n",
    "plt.title('Data - Reconstruction', fontsize = 20)\n",
    "vmax = np.max(np.abs(residual))\n",
    "plt.imshow(residual, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We detect footprints and peaks on the 2nd scale in the `detect` image defined above. Notice that most footprints have a single peak, while a few footprints, like the central region (peaks 20-23), have multiple peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scarlet.detect_pybind11 import get_footprints\n",
    "\n",
    "# Calculate isolated footprints and their maxima\n",
    "# in the 2nd wavelet scale.\n",
    "footprints = get_footprints(detect[1], min_separation=0, min_area=10, thresh=0)\n",
    "\n",
    "# Display all of the footprints\n",
    "footprint_img = np.zeros(detect.shape[1:])\n",
    "peaks = []\n",
    "for fp in footprints:\n",
    "    bbox = scarlet.detect.bounds_to_bbox(fp.bounds)\n",
    "    footprint_img[bbox.slices] = fp.footprint\n",
    "    peaks += list(fp.peaks)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(footprint_img, cmap=\"Greys\")\n",
    "\n",
    "# Display the peaks\n",
    "for k, peak in enumerate(peaks):\n",
    "    plt.text(peak.x, peak.y, str(k), color=\"r\")\n",
    "plt.show()\n",
    "\n",
    "# Now display the peaks on the original image\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(img_rgb)\n",
    "for k, peak in enumerate(peaks):\n",
    "    plt.text(peak.x, peak.y, str(k), color=\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To model the LSB we want to remove all of the sources in the image that we believe are slight overdensities in the LSB and not galaxies within the LSB itself. If we do not remove those sources then they will be fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsb_sources = [3, 4, 5, 6, 7, 8, 9, 13, 16, 17, 18, 19, 21, 22, 26, 37]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model Frame and Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can fully specify the `Frame` and `Observation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_psf = scarlet.GaussianPSF(sigma = 0.8)\n",
    "\n",
    "model_frame = scarlet.Frame(\n",
    "    images.shape,\n",
    "    psf=model_psf,\n",
    "    channels=filters)\n",
    "\n",
    "observation = scarlet.Observation(\n",
    "    images, \n",
    "    psf=scarlet.ImagePSF(psf),\n",
    "    channels=filters).match(model_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Starlet Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize sources\n",
    "\n",
    "We now need to define sources that are going to be fit. The full model, which we will call `Blend`, is a collection of those sources. As mentioned previously, we chose to represent most components as `ExtendedSources`. The tidal features in the image and the extended features are modeled by 3 `StarletSources`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = [(peak.y, peak.x) for peak in peaks]\n",
    "sources, skipped = scarlet.initialization.init_all_sources(model_frame,\n",
    "                                                           centers,\n",
    "                                                           observation,\n",
    "                                                           max_components=1,\n",
    "                                                           min_snr=50,\n",
    "                                                           thresh=1,\n",
    "                                                           fallback=True,\n",
    "                                                           silent=True,\n",
    "                                                           set_spectra=False\n",
    "                                                          )\n",
    "\n",
    "# Remove sources that we believe to be part of the LSB galaxy\n",
    "for k in lsb_sources:\n",
    "    sources[k] = scarlet.NullSource(model_frame)\n",
    "\n",
    "# Use a random seed to get consistent models in this demo\n",
    "np.random.seed(0)\n",
    "\n",
    "# Add a few starlet components to fit the LSB and tidal feature\n",
    "lsb_components = 3\n",
    "for k in range(lsb_components):\n",
    "    sources.append(scarlet.source.StarletSource(\n",
    "        model_frame,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Fit Model\n",
    "The `Blend` class represents the sources as a tree and has the machinery to fit all of the sources to the given images. In this example the code is set to run for a maximum of 200 iterations, but will end early if the likelihood and all of the constraints converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)\n",
    "%time it, logL = blend.fit(200, e_rel=1e-4, min_iter=100)\n",
    "print(f\"scarlet ran for {it} iterations to logL = {logL}\")\n",
    "scarlet.display.show_likelihood(blend)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Full Scene\n",
    "\n",
    "We will use `scarlet.display.show_scene` to render the entire scene. We then show model and data with the same $sinh^{-1}$ stretch and the residuals with a linear stretch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_scene(sources, \n",
    "                           norm=norm, \n",
    "                           observation=observation, \n",
    "                           show_rendered=True, \n",
    "                           show_observed=True, \n",
    "                           show_residual=True,\n",
    "                          )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Source Models\n",
    "\n",
    "We will now inspect the model for each source, in its original frame and in its observed frame by leveraging the `show_sources` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(sources, \n",
    "                             norm=norm, \n",
    "                             observation=observation,\n",
    "                             show_rendered=True, \n",
    "                             show_observed=True,\n",
    "                             add_boxes=True\n",
    "                            )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtracting the LSBG components\n",
    "\n",
    "Inspecting the source models above we see that scarlet initialization is unable to properly deblend sources 15, 25, and 32, as their flux is dominated by flux from the LSB galaxy. So we include them in the LSB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsbg = (\n",
    "    sources[-lsb_components].get_model()\n",
    "    + sources[15].get_model(frame=model_frame)\n",
    "    + sources[25].get_model(frame=model_frame)\n",
    "    + sources[32].get_model(frame=model_frame)\n",
    ")\n",
    "model = blend.get_model() - lsbg\n",
    "lsbg = observation.render(lsbg)\n",
    "\n",
    "\n",
    "\n",
    "res_rgb = scarlet.display.img_to_rgb(images-lsbg, norm=norm)\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "lsbg_rgb = scarlet.display.img_to_rgb(lsbg, norm=norm)\n",
    "model_rgb = scarlet.display.img_to_rgb(images-model, norm=norm)\n",
    "\n",
    "plt.figure(figsize = (30,15))\n",
    "plt.subplot(131)\n",
    "plt.title(\"Image\")\n",
    "plt.imshow(img_rgb)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(res_rgb)\n",
    "plt.title(\"Image - LSB\")\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(lsbg_rgb)\n",
    "plt.title(\"LSB\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

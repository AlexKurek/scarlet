{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet toy-model\n",
    "\n",
    "This tutorial goes through the same example as the Quickstart Guide but shows how to use `WaveletSource` instead of pixelated sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import numpy as np\n",
    "import scarlet\n",
    "import astropy.io.fits as fits\n",
    "import sep \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a superior colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='gist_stern', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Display Data\n",
    "\n",
    "We load an example data set (here an image cube with 5 bands) *and* a detection catalog.\n",
    "If such a catalog is not available packages like [SEP](http://sep.readthedocs.io/) and [photutils](https://photutils.readthedocs.io/en/stable/) will happily generate one, but for this example we use part of the detection catalog generated by the [LSST DM stack](https://github.com/lsst). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample images\n",
    "images = fits.open('../../data/hsc_ra=150.24071_dec=2.06514.fits')[0].data\n",
    "filters = ['g','r','i','z','y']\n",
    "psfs = fits.open('../../data/psf_hsc_ra=150.24071_dec=2.06514.fits')[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we detect the sources in the image and build a catalog of sources to deblend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCatalog(datas, lvl=3, wave=True):\n",
    "    ''' Creates a detection catalog by combining low and high resolution data\n",
    "    Parameters\n",
    "    ----------\n",
    "    datas: array\n",
    "        array of Data objects\n",
    "    lvl: int\n",
    "        detection lvl\n",
    "    wave: Bool\n",
    "        set to True to use wavelet decomposition of images before combination\n",
    "    Returns\n",
    "    -------\n",
    "    catalog: sextractor catalog\n",
    "        catalog of detected sources\n",
    "    bg_rms: array\n",
    "        background level for each data set\n",
    "    '''\n",
    "    if type(datas) is np.ndarray:\n",
    "        hr_images = datas / np.sum(datas, axis=(1, 2))[:, None, None]\n",
    "        # Detection image as the sum over all images\n",
    "        detect_image = np.sum(hr_images, axis=0)\n",
    "    else:\n",
    "        data_lr, data_hr = datas\n",
    "        # Create observations for each image\n",
    "        # Interpolate low resolution to high resolution\n",
    "        interp = interpolate(data_lr, data_hr)\n",
    "        # Normalisation of the interpolate low res images\n",
    "        interp = interp / np.sum(interp, axis=(1, 2))[:, None, None]\n",
    "        # Normalisation of the high res data\n",
    "        hr_images = data_hr.images / np.sum(data_hr.images, axis=(1, 2))[:, None, None]\n",
    "        # Detection image as the sum over all images\n",
    "        detect_image = np.sum(interp, axis=0) + np.sum(hr_images, axis=0)\n",
    "        detect_image *= np.sum(data_hr.images)\n",
    "    if np.size(detect_image.shape) == 3:\n",
    "        if wave:\n",
    "            # Wavelet detection in the first three levels\n",
    "            wave_detect = Starlet(detect_image.mean(axis=0), lvl=4).coefficients\n",
    "            wave_detect[:, -1, :, :] = 0\n",
    "            detect = scarlet.Starlet(coefficients=wave_detect).image\n",
    "        else:\n",
    "            # Direct detection\n",
    "            detect = detect_image.mean(axis=0)\n",
    "    else:\n",
    "        if wave:\n",
    "            wave_detect = scarlet.Starlet(detect_image).coefficients\n",
    "            detect = wave_detect[0][0] + wave_detect[0][1] + wave_detect[0][2]\n",
    "        else:\n",
    "            detect = detect_image\n",
    "\n",
    "    bkg = sep.Background(detect)\n",
    "    catalog = sep.extract(detect, lvl, err=bkg.globalrms)\n",
    "\n",
    "    if type(datas) is np.ndarray:\n",
    "        bg_rms = scarlet.wavelet.mad_wavelet(datas)\n",
    "    else:\n",
    "        bg_rms = []\n",
    "        for data in datas:\n",
    "            bg_rms.append(scarlet.wavelet.mad_wavelet(data.images))\n",
    "\n",
    "    return catalog, bg_rms\n",
    "#Detection and background noise estimate\n",
    "catalog, bg_rms_hsc = makeCatalog(images, 1, 1)\n",
    "\n",
    "weights = np.ones_like(images) / (bg_rms_hsc**2)[:, None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows how the wavelet transform and inverse transform works in scarlet. As a check we make sure that the transform and its inverse lead to the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare a starlet object (and performs the transform)\n",
    "Sw = scarlet.Starlet(images, lvl = 4, direct = True)\n",
    "#This is the starlet transform as an array\n",
    "w = Sw.coefficients\n",
    "#The inverse starlet transform of w (new object otherwise, the tranform is not used)\n",
    "iw = Sw.image\n",
    "\n",
    "#The wavelet transform of the first slice of images in pictures:\n",
    "lvl = w.shape[1]\n",
    "plt.figure(figsize = (lvl*5,5))\n",
    "plt.suptitle('Wavelet coefficients')\n",
    "for i in range(lvl):\n",
    "    plt.subplot(1,lvl,i+1)\n",
    "    plt.title('scale'+str(i+1))\n",
    "    plt.imshow(w[0,i])\n",
    "    plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#Making sure we recover the original image:\n",
    "plt.figure(figsize = (30,10))\n",
    "plt.subplot(131)\n",
    "plt.title('Original image', fontsize = 20)\n",
    "plt.imshow(images[0])\n",
    "plt.colorbar()\n",
    "plt.subplot(132)\n",
    "plt.title('Starlet-reconstructed image', fontsize = 20)\n",
    "plt.imshow(iw[0])\n",
    "plt.colorbar()\n",
    "plt.subplot(133)\n",
    "plt.title('Absolute difference', fontsize = 20)\n",
    "plt.imshow((np.abs(iw[0]-images[0])))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word on starlets\n",
    "\n",
    "Starlets are a familly of functions that are generative of the ensemble of real matrices of finite sahpes and overcomplete. In that regard, shapelets have the flexibility to represent any pixelated 2-D profile. We take advantage of this property and use starlets to model sources with features that are too complex to be modeled with only assumptions of symmetry or monotonicity, such as irregular galaxies and spiral galaxies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Image Cube\n",
    "This is an example of how to display an RGB image from an image cube of multiband data. In this case the image uses a $sinh^{-1}$ function to normalize the flux in each filter consistently to create an RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarlet.display import AsinhMapping\n",
    "\n",
    "stretch = 0.2\n",
    "Q = 10\n",
    "norm = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "plt.imshow(img_rgb)\n",
    "\n",
    "# Mark all of the sources from the detection cataog\n",
    "for k, src in enumerate(catalog):\n",
    "    plt.text(src[\"x\"], src[\"y\"], str(k), color=\"red\")\n",
    "    plt.plot(src[\"x\"], src[\"y\"], 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the detected sources, it seems that sources 1 and 4 are individual components, while the central galaxy has a \"red\" component centered around 2 and a blue component particularly bright around 3 and 0. We will use this information to inform the choice of source types we use to model the scene.\n",
    "\n",
    "Here this procedure is done manually, but in the future, we expect that matching images with different colours and complex morphologies might help automating this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Frame and Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can fully specify the `Frame` and `Observation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_frame = scarlet.Frame(\n",
    "    images.shape,\n",
    "    psfs=psfs,\n",
    "    channels=filters)\n",
    "\n",
    "observation = scarlet.Observation(\n",
    "    images, \n",
    "    psfs=psfs, \n",
    "    weights=weights, \n",
    "    channels=filters).match(model_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize sources\n",
    "\n",
    "You now need to define sources that are going to be fit. The full model, which we will call `Blend`, is a collection of those sources. Has mentioned previously, we chose to represent components 1 and 4 as `ExtendedSources`, while the rest of the scene is modeled by 2 `StarletSources` with different colours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sources = []\n",
    "for k,src in enumerate(catalog):\n",
    "    if k in [2,0]:\n",
    "        new_source = scarlet.StarletSource(model_frame, \n",
    "                        (src[\"x\"], src[\"y\"]), observation, \n",
    "                        starlet_thresh = 1)\n",
    "        sources.append(new_source)\n",
    "    if k in [4,1]:\n",
    "        new_source = scarlet.ExtendedSource(model_frame, (src['y'], src['x']), observation)\n",
    "        sources.append(new_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit Model\n",
    "The `Blend` class represents the sources as a tree and has the machinery to fit all of the sources to the given images. In this example the code is set to run for a maximum of 200 iterations, but will end early if the likelihood and all of the constraints converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)\n",
    "%time blend.fit(200, e_rel=1e-4)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(-np.array(blend.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Full Scene\n",
    "\n",
    "We will use `scarlet.display.show_scene` to render the entire scene. We then show model and data with the same $sinh^{-1}$ stretch and the residuals with a linear stretch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_scene(sources, \n",
    "                           norm=norm, \n",
    "                           observation=observation, \n",
    "                           show_rendered=True, \n",
    "                           show_observed=True, \n",
    "                           show_residual=True,\n",
    "                           add_boxes=True,\n",
    "                          )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Source Models\n",
    "\n",
    "We will now inspect the model for each source, in its original frame and in its observed frame by leveraging the `show_sources` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(sources, \n",
    "                             norm=norm, \n",
    "                             observation=observation,\n",
    "                             show_rendered=True, \n",
    "                             show_observed=True,\n",
    "                             add_boxes=True\n",
    "                            )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
